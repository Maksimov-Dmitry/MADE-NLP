{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework02: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   128    0   128    0     0    322      0 --:--:-- --:--:-- --:--:--   323\n",
      "100   342  100   342    0     0     91      0  0:00:03  0:00:03 --:--:--   145\n",
      "100  119M  100  119M    0     0  5038k      0  0:00:24  0:00:24 --:--:-- 5819k\n",
      "x Train_rev1.csv\n",
      "--2023-02-20 13:28:25--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
      "Resolving raw.githubusercontent.com... 2606:50c0:8001::154, 2606:50c0:8003::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1469 (1.4K) [text/plain]\n",
      "Saving to: 'network.py.1'\n",
      "\n",
      "network.py.1        100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-20 13:28:25 (9.66 MB/s) - 'network.py.1' saved [1469/1469]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "# !curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
    "# !tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "# data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [],
   "source": [
    "# run this cell if you have downloaded the dataset on the seminar\n",
    "data = pd.read_csv(\"Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12612844</td>\n",
       "      <td>Modelling and simulation analyst</td>\n",
       "      <td>Mathematical Modeller / Simulation Analyst / O...</td>\n",
       "      <td>Hampshire, South East, South East</td>\n",
       "      <td>Hampshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 40000/annum 20-40K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12613049</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Engineering Systems Analyst / Mathematical Mod...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 30000/annum 25K-30K negotiable</td>\n",
       "      <td>27500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12613647</td>\n",
       "      <td>Pioneer, Miser Engineering Systems Analyst</td>\n",
       "      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>\n",
       "      <td>Surrey, South East, South East</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  12612628                        Engineering Systems Analyst   \n",
       "1  12612830                            Stress Engineer Glasgow   \n",
       "2  12612844                   Modelling and simulation analyst   \n",
       "3  12613049  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  12613647         Pioneer, Miser Engineering Systems Analyst   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "2  Mathematical Modeller / Simulation Analyst / O...   \n",
       "3  Engineering Systems Analyst / Mathematical Mod...   \n",
       "4  Pioneer, Miser  Engineering Systems Analyst Do...   \n",
       "\n",
       "                         LocationRaw LocationNormalized ContractType  \\\n",
       "0            Dorking, Surrey, Surrey            Dorking          NaN   \n",
       "1        Glasgow, Scotland, Scotland            Glasgow          NaN   \n",
       "2  Hampshire, South East, South East          Hampshire          NaN   \n",
       "3     Surrey, South East, South East             Surrey          NaN   \n",
       "4     Surrey, South East, South East             Surrey          NaN   \n",
       "\n",
       "  ContractTime                       Company          Category  \\\n",
       "0    permanent  Gregory Martin International  Engineering Jobs   \n",
       "1    permanent  Gregory Martin International  Engineering Jobs   \n",
       "2    permanent  Gregory Martin International  Engineering Jobs   \n",
       "3    permanent  Gregory Martin International  Engineering Jobs   \n",
       "4    permanent  Gregory Martin International  Engineering Jobs   \n",
       "\n",
       "                                SalaryRaw  SalaryNormalized        SourceName  \n",
       "0              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  \n",
       "1              25000 - 35000/annum 25-35K             30000  cv-library.co.uk  \n",
       "2              20000 - 40000/annum 20-40K             30000  cv-library.co.uk  \n",
       "3  25000 - 30000/annum 25K-30K negotiable             27500  cv-library.co.uk  \n",
       "4              20000 - 30000/annum 20-30K             25000  cv-library.co.uk  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232074</th>\n",
       "      <td>72460921</td>\n",
       "      <td>Risky Business  Nonlife Risk Analytics</td>\n",
       "      <td>A unique opportunity for a nonlife actuary/stu...</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Star Actuarial Futures</td>\n",
       "      <td>Accounting &amp; Finance Jobs</td>\n",
       "      <td>up to 80k + bonus + benefits</td>\n",
       "      <td>80000</td>\n",
       "      <td>actuaryjobs.co.uk</td>\n",
       "      <td>11.289794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110986</th>\n",
       "      <td>69681482</td>\n",
       "      <td>ACCOUNT MANAGER  DESIGN AGENCY  HOME ENTS</td>\n",
       "      <td>ACCOUNT MANAGER DESIGN AGENCY HOME ENTERTAINME...</td>\n",
       "      <td>Greater London</td>\n",
       "      <td>London</td>\n",
       "      <td>full_time</td>\n",
       "      <td>permanent</td>\n",
       "      <td>REGENT SELECTION LTD</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>35,000 - 40,000</td>\n",
       "      <td>37500</td>\n",
       "      <td>jobs.guardian.co.uk</td>\n",
       "      <td>10.532123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143985</th>\n",
       "      <td>70627588</td>\n",
       "      <td>Senior Charge Nurse  Older People's Services (...</td>\n",
       "      <td>NHS Shetland Give your career a breath of fres...</td>\n",
       "      <td>Shetland , Scotland</td>\n",
       "      <td>Shetlands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NHS Shetland</td>\n",
       "      <td>Healthcare &amp; Nursing Jobs</td>\n",
       "      <td>30,460.00 - 40,157.00 per annum</td>\n",
       "      <td>35308</td>\n",
       "      <td>rcnbulletinjobs.co.uk</td>\n",
       "      <td>10.471893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                              Title  \\\n",
       "232074  72460921             Risky Business  Nonlife Risk Analytics   \n",
       "110986  69681482          ACCOUNT MANAGER  DESIGN AGENCY  HOME ENTS   \n",
       "143985  70627588  Senior Charge Nurse  Older People's Services (...   \n",
       "\n",
       "                                          FullDescription  \\\n",
       "232074  A unique opportunity for a nonlife actuary/stu...   \n",
       "110986  ACCOUNT MANAGER DESIGN AGENCY HOME ENTERTAINME...   \n",
       "143985  NHS Shetland Give your career a breath of fres...   \n",
       "\n",
       "                LocationRaw LocationNormalized ContractType ContractTime  \\\n",
       "232074               London             London          NaN    permanent   \n",
       "110986       Greater London             London    full_time    permanent   \n",
       "143985  Shetland , Scotland          Shetlands          NaN          NaN   \n",
       "\n",
       "                       Company                   Category  \\\n",
       "232074  Star Actuarial Futures  Accounting & Finance Jobs   \n",
       "110986    REGENT SELECTION LTD              Teaching Jobs   \n",
       "143985            NHS Shetland  Healthcare & Nursing Jobs   \n",
       "\n",
       "                              SalaryRaw  SalaryNormalized  \\\n",
       "232074     up to 80k + bonus + benefits             80000   \n",
       "110986                  35,000 - 40,000             37500   \n",
       "143985  30,460.00 - 40,157.00 per annum             35308   \n",
       "\n",
       "                   SourceName  Log1pSalary  \n",
       "232074      actuaryjobs.co.uk    11.289794  \n",
       "110986    jobs.guardian.co.uk    10.532123  \n",
       "143985  rcnbulletinjobs.co.uk    10.471893  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239768it [00:13, 17431.38it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()# <YOUR CODE HERE>\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598827"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 201127\n",
      "('and', 2598827)\n",
      "('.', 2471477)\n",
      "(',', 2266256)\n",
      "('the', 2036428)\n",
      "('to', 1977039)\n",
      "...\n",
      "('dbms_stats', 1)\n",
      "('dbms_output', 1)\n",
      "('dbms_job', 1)\n",
      "Correct!\n",
      "Vocabulary size: 33795\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10705 29830  2143     1     1]\n",
      " [14875  2817     1     1     1]\n",
      " [27345 10107    15 15069 10702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  191814\n",
      "Validation size =  47954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[ 2546, 26688, 18670,   195,  4938,  9000, 18670,   195, 30332,\n",
       "         18670],\n",
       "        [12890,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1],\n",
       "        [16378,  4938,  2143, 12105, 27463,     1,     1,     1,     1,\n",
       "             1]], dtype=int32),\n",
       " 'FullDescription': array([[16658, 30725,   891, ..., 27463,   156, 27183],\n",
       "        [    0, 16289,   965, ...,     1,     1,     1],\n",
       "        [16378,  4938,  2143, ...,     1,     1,     1]], dtype=int32),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1570],\n",
       "        [0.4624],\n",
       "        [0.3634]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 550)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['FullDescription'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "model = simple_model\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "        batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "\n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from '/Users/dmitriimaksimov/Desktop/GitHub/MADE-NLP/natural-language-processing/homeworks/assignment02_three_headed_network/network.py'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell if you updated the file with network source code\n",
    "import imp\n",
    "imp.reload(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "\n",
    "    # this parameter defines the number of the inputs in the layer,\n",
    "    # which stands after the concatenation. In should be found out by you.\n",
    "    concat_number_of_features=64 * 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r_/bq4swdms3vj5wr80yf1vm4nh0000gn/T/ipykernel_39623/3927902415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# train with backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training pipeline comes here (almost the same as for the simple_model)\n",
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "model = model\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "        batch = [\n",
    "            torch.tensor(batch['Title'], dtype=torch.long),\n",
    "            torch.tensor(batch['FullDescription'], dtype=torch.long),\n",
    "            torch.tensor(batch['Categorical'])\n",
    "        ]\n",
    "\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "\n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['Categorical'])\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        \n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Both the notebook and the `.py` file are required to submit this homework.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
